{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "yz4C-rzVuXeU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchsummary\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data in json format\n",
        "\n",
        "os.makedirs(\"images_train\", exist_ok=True)\n",
        "os.makedirs(\"images_test\", exist_ok=True)\n",
        "\n",
        "\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Create JSON files for training and test datasets\n",
        "def create_json(dataset, json_filename):\n",
        "    data_list = []\n",
        "    for i, (image, label) in enumerate(dataset):\n",
        "        data_list.append({\"img_path\": f\"{i}.png\", \"labels\": label})\n",
        "        base_name = os.path.basename(json_filename)\n",
        "        type_data = base_name.split('_')[0] # returns train or test\n",
        "        directory = \"images_\" + type_data\n",
        "        image_path = os.path.join(directory, f\"{i}.png\")\n",
        "        torchvision.utils.save_image(image, image_path)\n",
        "    with open(json_filename, 'w') as json_file:\n",
        "      for data in data_list:\n",
        "        json.dump(data, json_file)\n",
        "        json_file.write('\\n')\n",
        "\n",
        "create_json(train_data, \"train_data.json\")\n",
        "create_json(test_data, \"test_data.json\")"
      ],
      "metadata": {
        "id": "ZvZShlYQ4s6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e492b4fa-81df-4693-b32f-33dfdcea69db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10759030.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 201313.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3836116.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 13957515.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset customed\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "\n",
        "    def __init__(self, json_filename, transform=None):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            json_filename (string): Json file with images paths and labels.\n",
        "            transform (callable, optional): Optional transform to be applied.\n",
        "        \"\"\"\n",
        "        self.data_list = []\n",
        "        with open(json_filename, 'r') as file:\n",
        "          for line in file:\n",
        "              loaded_dict = json.loads(line)\n",
        "              self.data_list.append(loaded_dict)\n",
        "        self.transform = transform\n",
        "        self.json_filename = json_filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_path_aux = self.data_list[idx]['img_path']\n",
        "      base_name = os.path.basename(self.json_filename)\n",
        "      type_data = base_name.split('_')[0]\n",
        "      directory = \"images_\" + type_data\n",
        "      img_path = os.path.join(directory, img_path_aux)\n",
        "      image = Image.open(img_path)\n",
        "      if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "      label = self.data_list[idx]['labels']\n",
        "      return image, label\n",
        "\n",
        "\n",
        "# Transforming the image in getitem\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    #transforms.RandomCrop((224,224))\n",
        "    transforms.Grayscale(num_output_channels=1), # 28x28x1\n",
        "    transforms.ToTensor()\n",
        "    #transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dataset = CustomImageDataset(\"train_data.json\", transform)\n",
        "test_dataset = CustomImageDataset(\"test_data.json\", transform)"
      ],
      "metadata": {
        "id": "DQduwX-hvknz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code divides the training in train-val data\n",
        "\n",
        "# 70 % of 60.000 training and 30% validation\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "print(\"Train size: \", train_size, \"\\nValidation size: \", val_size, \"\\nTest size: \", len(test_dataset))\n",
        "new_train_dataset, new_val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(new_val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsKc7YVV96ld",
        "outputId": "f62e4125-3843-44ed-fa50-50964c7eeee7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:  48000 \n",
            "Validation size:  12000 \n",
            "Test size:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE: LeNet-5 architecture\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            # convolution: 6 out channels/filters = 6@28x28, a convolution of 5x5 is applied -> kernel_size 5\n",
        "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2),   # padding 2 because input images are 28x28 (not 32x32)\n",
        "            nn.ReLU(),\n",
        "            # average pooling\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),  # 14*14\n",
        "            # convolution: it recieves 6 from previous convolution and now 16@10x10\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=16*5*5, out_features=120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=84, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.classifier(self.feature(x))\n",
        "\n",
        "\n",
        "# Kaiming Uniform initialization\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "        init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # in Alex computer no cuda, already checked, Alimo you could check\n",
        "\n",
        "baseline_model = LeNet5().to(device)\n",
        "baseline_model.apply(init_weights)\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "torchsummary.summary(baseline_model, input_size=(1,28 , 28))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3uH41yx6mCK",
        "outputId": "55f9c546-a7ba-4e3a-8a1f-ac0f3c1ed3d0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "              ReLU-2            [-1, 6, 28, 28]               0\n",
            "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
            "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
            "              ReLU-5           [-1, 16, 10, 10]               0\n",
            "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
            "           Flatten-7                  [-1, 400]               0\n",
            "            Linear-8                  [-1, 120]          48,120\n",
            "              ReLU-9                  [-1, 120]               0\n",
            "           Linear-10                   [-1, 84]          10,164\n",
            "             ReLU-11                   [-1, 84]               0\n",
            "           Linear-12                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.11\n",
            "Params size (MB): 0.24\n",
            "Estimated Total Size (MB): 0.35\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epochs = 5):\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #print(images.shape)\n",
        "            # Forward Pass\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "\n",
        "            # Backward Pass\n",
        "            loss.backward()\n",
        "            optimizer.step() # updates model parameters using gradient computings by back propagation and applies the optimization algo\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if batch_idx % 100 == 99:\n",
        "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {running_loss/100:.4f}')\n",
        "                running_loss = 0.0\n"
      ],
      "metadata": {
        "id": "9-A2iQ9lCZfy"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(baseline_model, device, train_loader, optimizer, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UEhRS70CPBi",
        "outputId": "4067c495-a924-4e70-89bc-f1d8ec1abf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100/1500, Loss: 1.1154\n",
            "Epoch 1, Batch 200/1500, Loss: 0.6271\n"
          ]
        }
      ]
    }
  ]
}